{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd370de3-c897-40bb-9753-bd985fbc2699",
   "metadata": {},
   "source": [
    "# Train Your Own AI Models!\n",
    "\n",
    "Note: Before starting click the two cells below and press `CTRL` + `ENTER` on your keyboard. This will install and import the packages before we start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f842a34-2d4b-486a-bac3-b091741a6107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchsummary in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: rich in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (13.7.1)\n",
      "Requirement already satisfied: ipywidgets in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (8.1.3)\n",
      "Requirement already satisfied: scikit_learn in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: filelock in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: numpy in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from rich) (2.16.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipywidgets) (5.11.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit_learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit_learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit_learn) (3.2.0)\n",
      "Requirement already satisfied: backcall in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: stack-data in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/stmball/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchsummary rich ipywidgets scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49afe0c8-c659-452a-a32f-93797f83e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from rich.progress import track\n",
    "\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a97cd-85bc-4ba3-a618-898198e070ce",
   "metadata": {},
   "source": [
    "# Welcome to the $NAME AI Challenge!\n",
    "\n",
    "We've all heard about artificial intelligence (AI) changing the world, but did you know it's making waves in how we care for our eyes? Today, we're going to explore some amazing ways that AI is helping doctors keep our vision sharp and healthy. \n",
    "\n",
    "AI is all around us, being used for everything from unlocking how drugs interact with our bodies to trying to defend against cyberattacks to make the internet safer; but how does it work?\n",
    "\n",
    "In our session today, we'll take a look at:\n",
    "\n",
    "1. What is AI, and how do modern AI models work?\n",
    "2. How can we train our own AI to detect eye disease?\n",
    "3. What are some of the considerations we need to consider when using this model?\n",
    "\n",
    "So with that said, let's get stuck in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b357465-a021-4d5a-bff4-312fcb028d02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# What is AI, and how does it work?\n",
    "\n",
    "AI models are computer programs that aim to perform complex tasks to save us time and effort. Sometimes this is about performing something tedious for us, but fairly difficult for simple computer programs (for example, saying if an image is of a \"cat\" or a \"dog\"), but sometimes it allows us to analyse huge datasets in ways we previously couldn't (for example, detecting fraudulant credit card transactions). \n",
    "\n",
    "Most cutting-edge AI works using *neural networks*; these are massive mathematical models originally developed to imitate how our brains worked! These models work by having millions (or  billions now!) of *parameters* that change as the model learns, improving the model as training continues.\n",
    "\n",
    "The way a model \"learns\" is by having a *loss function*; this is a general measure of how \"well\" the model is doing. The higher the loss, the worse the model performs. Sometimes this loss is obvious (e.g. - did the model correctly guess \"cat\" for cat images?), but for more advanced models loss functions can get quite creative.\n",
    "\n",
    "SAM NOTE: Write some more here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3a99c-5d4f-4367-8d48-a0954be1e692",
   "metadata": {},
   "source": [
    "# A brief (!) detour - Python and coding\n",
    "\n",
    "To train AI, we need a way of talking to our computer - and programming languages are the way to go about doing this. By using code, we can give instructions to our computer for it to perform billions of computations during training. \n",
    "\n",
    "One of the most popular coding languages to train AI is Python - which is what we're using in this document. By using Python, we have access to a huge number of AI tools that make training significantly easier. \n",
    "\n",
    "Using these notebooks, we can run code alongside reading text and viewing images. Any time you see a block like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c92fd7e-2db5-462c-bdfb-ada5cc442f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054597c-ec2f-47fe-a14c-8fb75ab73256",
   "metadata": {},
   "source": [
    "You can run the cell and any outputs will show below. Try running the cell by clicking it and pressing SHIFT + ENTER on your keyboard!\n",
    "\n",
    "Learning Python is a huge task in itself, but well worth it; if training your own AI interests you in learning more, please let us know and we can signpost you to some good resources for learning more!\n",
    "\n",
    "In this session, we'll code together - we'll explain the bits that are new, and you'll be able to tinker with the code and write your own to make the AI work. Let's start by looking at the above block of code.\n",
    "\n",
    "`print` is a *function* - these are like digital machines that accept inputs (in this case, the text \"Hello world!\"), and do something with it (in this case, show it in the output box below. In fact, \"inside\" the function is actually more Python code that runs in the background, and we can write our own functions to organise our code in an easier way.\n",
    "\n",
    "## Challenges\n",
    "\n",
    "1. Try changing text between the speech marks above and see what happens.\n",
    "2. The `len` function gives us the length of the object we enter in - for text this is the number of letters including spaces. How many letters does `\"The quick brown fox jumps over the lazy dog have\"` (including spaces)?\n",
    "3. `sorted` will sort an object into ascending order (in text's case, this is alphabetical order of letters). However to use this in an interesting way, we need to introduce lists. List are a collection of elements. Here we are *assigning* the list to the variable `a` - this means that whenever Python \"sees\" `a`, it will `think` of the value it is assigned to. Try running the `sorted` function on `a` and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2ae093-769b-4a1a-a5e8-48af841e5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how lists are written!\n",
    "a = [5, 13, 2, 1, 3, 8, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc122a3-39eb-4aca-ace2-76ade54b319b",
   "metadata": {},
   "source": [
    "# Training our own AI\n",
    "\n",
    "Let's now try and train our own AI for eye healthcare - we are going to build a model for detecting Glaucoma from fundus photography.\n",
    "\n",
    "Glaucoma is a common eye condition that is the leading cause of blindness in the UK. Clinicans will take a photo of the back of the eye and examine the images for features that are characteristic to the condition.\n",
    "\n",
    "![Example of a healthy retina](img/ex1.jpg)\n",
    "![Example of another healthy retina](img/ex2.jpg)\n",
    "\n",
    "We have an open-source dataset from the Rotterdam EyePACS AIROGS challenge (https://www.kaggle.com/datasets/deathtrooper/eyepacs-airogs-light?resource=download) that we are going to use to train our AI model. Under the `data/train` directory, we have 2500 positive (RG) and 2500 negative cases (NRG) of glaucoma.\n",
    "\n",
    "Our first job is to create Python object that contains all of our data ready to be trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69b166c-2e33-46bb-9a88-3ebe549ceb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FundusDataset(Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_path = self.files[idx]\n",
    "        \n",
    "        image = read_image(image_path)\n",
    "        \n",
    "        label = 0 if \"NRG\" in str(image_path) else 1\n",
    "\n",
    "        return image.float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b6db79-c23f-40ed-b608-28f4cfc881ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get all the image files in the training folder.\n",
    "# .glob finds files based on a pattern; ** means \"any folder\"\n",
    "# and * means \"any file\" - as long as it ends in .jpg!\n",
    "\n",
    "files = list(Path(\"./data/train\").glob(\"**/*.jpg\"))\n",
    "\n",
    "# Randomly shuffle this list to get a good mix of positive and negative eyes.\n",
    "random.shuffle(files)\n",
    "\n",
    "# 10k eyes is too much to work with now, so to speed things up we can take the first 100\n",
    "files = files[:100]\n",
    "\n",
    "# We have created the FundusDataset object to convert this list\n",
    "# into a type of object PyTorch needs. It's fairly straightforward,\n",
    "# but the code is a bit challenging, so we've collapsed it above.\n",
    "training_dataset = FundusDataset(files)\n",
    "\n",
    "# Next, we convert this into a \"DataLoader\" - this prepares the \n",
    "# data ready to be put into the AI model!\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b2b37-56f4-4603-a237-060e87135dd4",
   "metadata": {},
   "source": [
    "The next thing we want to do is load and train the model. We are going to be doing this using the ResNet model (https://arxiv.org/abs/1512.03385), a well established, mature network that performs well on classification tasks.\n",
    "\n",
    "We do not need to know exactly how this AI works (although that's the excitement of AI research!), but we only need to know that we need to set up a few things for training to take place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1015e1-e222-4a9c-ac07-9bae6dcb707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/stmball/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-11           [-1, 64, 64, 64]               0\n",
      "           Conv2d-12           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 64, 64]             128\n",
      "             ReLU-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 64, 64]             128\n",
      "             ReLU-17           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-18           [-1, 64, 64, 64]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "           Conv2d-24          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 32, 32]             256\n",
      "             ReLU-26          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "             ReLU-30          [-1, 128, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 82.00\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 125.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# We can download the untrained model as follows.\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', num_classes=2, weights=None)\n",
    "\n",
    "# The Loss function will decide how badly the model is doing\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# The optimizer will work to reduce the loss functino by changing the model parameters\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# This moves the model object to the right bit of memory\n",
    "model.to(device)\n",
    "\n",
    "# Print a summary of the model\n",
    "summary(model, input_size=(3,256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33985999-4d99-41aa-ae2c-85c0397e753a",
   "metadata": {},
   "source": [
    "Now we can get to training our model; this is the part where we write the least code, but the computer does the most work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a08734e-4ba5-456f-8228-63ea96bccfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a129f341cbfd407b80e87919476658a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64696e9d511e430a8199140309b92b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 0.845574676990509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacfcfba5720418e954299a4b24c254b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss 0.7649611532688141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc4711ea9e7446d9133af03e728a6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 loss 0.6679827868938446\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8d8f07a630470bbc83fee78c28ab77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss 0.621123880147934\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe4fcc755114803bc76ca2b73aaa259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 loss 0.5988236963748932\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1e373505604d7f9b87d47e437eed41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 loss 0.5736713111400604\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78b1e910a144fc0a9be4364e9cc89bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 loss 0.5182096064090729\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1232fc38982540e48639bb0a1accfde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 loss 0.4839670658111572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6363038587734c719abb6ae908834f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 loss 0.46443256735801697\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 loss 0.4275321662425995\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in track(training_dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch \n",
    "    print(epoch, \"loss\", running_loss / len(training_dataloader))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72556f2-2bdc-461a-a4ba-bd1378a8cfe5",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "Now that we have trained the model; we want to test how well the model is doing. When testing our models, it's unfair to use the data the model already has; we don't want to test the *memory* of the model, but the *understanding* of the model to look at the typical features of glaucoma. Typically, we split the dataset to reserve some images specifically for testing for this purpose - in fact, the `data` folder has a specific foldder for us here. All we need to do is set up the images in the same way as training and get the outputs.\n",
    "\n",
    "From there, we can use some measures to see how well our model stacks up. There are plenty of metrics that all measure slightly different things; and later we'll think about the pros and cons of different ones. For now, we'll be using the `f1_score`, which is a fairly standard place to start for classification tasks. Let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ef9b9e3-d07e-47c7-9413-0220bdd82930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11f6f3a0bcc449daecd09da4a1aa791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This process is exactly the same as the training dataloaders\n",
    "# but we point the program to the \"test\" folder instead.\n",
    "\n",
    "files = list(Path(\"./data/test\").glob(\"**/*.jpg\"))\n",
    "random.shuffle(files)\n",
    "files = files[:100]\n",
    "testing_dataset = FundusDataset(files)\n",
    "testing_dataloader = DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "truth = []\n",
    "predictions = []\n",
    "\n",
    "for data in track(testing_dataloader):\n",
    "    \n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    truth.append(labels.numpy())\n",
    "    \n",
    "    outputs = model(inputs).detach().numpy().argmax(axis=1)\n",
    "\n",
    "    predictions.append(outputs)\n",
    "\n",
    "truth = np.concatenate(truth)\n",
    "predictions = np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "626c3e22-5492-48d7-b718-60bd5f14ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0\n",
      " 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1]\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.8785046728971964\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "accuracy = accuracy_score(truth, predictions)\n",
    "f1 = f1_score(truth, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b49397-4841-45b7-a96d-e9a0b689c017",
   "metadata": {},
   "source": [
    "# Thinking about AI Impact\n",
    "\n",
    "If you've got this far, you have successfully trained your own AI to detect eye disease. Well done! Let's think about some considerations when using this model.\n",
    "\n",
    "## Model Design Decisions\n",
    "\n",
    "Throughout this code we have made many decisions; some stylistic (e.g. the usage of `Path`) and others critical to how the model works (e.g. the learning rate, model design, etc). Most of these decisions are reached after some experimentation; for example see what happens if you increase or decrease the learning rate - does the model get better quicker?\n",
    "\n",
    "## Model Validity and Metrics\n",
    "\n",
    "We have measured the F1 score of the model - but this metric doesn't mean much in a vaccum; how good is the F1 score that we got in real terms? Ideally, we'd look at what a current clinical accuracy is to see if we're getting close to reaching expert accuracy, or if we're far off. If we're beating the experts, fantastic! However if we're not as good as clinicians, we can do additional analysis into why that is the case. Maybe we have a small number of cases that are difficult for AI but easy for experts. Maybe our training set isn't representitive of the whole population?\n",
    "\n",
    "Not thinking about these problems is what leads to systematic imbalances in AI, and what drives inequality in AI outcomes. If the dataset is not representitive of the general population (e.g. does not contain BAME samples), then the outputs will have far lower performance for these groups. It's our job as AI researchers to think about these challenges and solve them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
